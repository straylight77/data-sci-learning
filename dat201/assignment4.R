#| *************************************************************************
#| *                                                                       *
#| *                          ASSIGNMENT #4                                *
#| *                                                                       *
#| *************************************************************************
#|
#| All of my comments are prepended with the pipe character

# Please practice the code and explain
# 1. every single results
# 2. every argument/parameters
# 3. Explain the followings - 

#| https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/

# what is Confusion Matrix
#| A confusion matrix visualizes and summarizes the performance of a 
#| classification algorithm.  It compares the number of predicted values and 
#| the true actual values.  There are 4 basic metrics:
#|    True Positives (TP): predicted positive and correct
#|    True Negatives (TN): predicted negative and correct
#|    False Positives (FP): predicted positive but incorrect
#|    False Negatives (FN): predicted negative but incorrect
#| For example:
#|             Predicted 
#|              P    N
#|   Real  P   TP   FN
#|         N   FP   TN

# how to get Accuracy - waht does it gives
#| ACCURACY = (TP + TN) / (TP + TN + FP + FN)
#| Overall, how often is the prediction model correct?

# what does "No Information Rate" means - why do we need it
#| The largest proportion of the observed classes. In the example below, the 
#| value 0.6095 indicates there are more "n" classes than "y" in the training
#| data set.

# what is Kappa? What does it measures
#| How well the classifier performed as compared to how well it would have 
#| performed simply by chance.  

# what does Mcnemar's test do here in the classification/decission tree results
#| The McNemar’s test is checking if the disagreements between two cases match. 
#| Technically, this is referred to as the homogeneity of the contingency table 
#| (specifically the marginal homogeneity). Therefore, the McNemar’s test is a 
#| type of homogeneity test for contingency tables.
#|    e.g. used in medicine to compare the effect of a treatment against a control.
#|    p > alpha: fail to reject H0, no difference in the disagreement 
#|      (e.g. treatment had no effect).
#|    p <= alpha: reject H0, significant difference in the disagreement 
#|      (e.g. treatment had an effect).

# what is "        Sensitivity  " - why do we need it.
#| SENSITIVITY = TP / (TP + FN)
#| Also known as: recall, hit rate, true positive rate
#| When the real value is positive, how often does it predict positive?
#| A good metric to use when we are focusing on limiting our false negatives.
#| e.g. diagnosing COVID-19; want to avoid people spreading the disease with a 
#| negative test.

# what is "         Specificity " - why do we need it.     
#| SPECIFICITY = TN / (TN + FP)
#| Also known as: selectivity, true negative rate
#| When the real value is negative, how often does it predict negative?

# what is "      Pos Pred Value " - why do we need it.     
#| POSITIVE PREDICTIVE VALUE (PPV) = TP / (TP + FP)
#| Also called: precision
#| A good measure to use when we want to focus on limiting false positives. 

# what is "      Neg Pred Value " - why do we need it.
#| NEGATIVE PREDICTIVE VALUE (NPV) = TN / (TN + FN)
#| 

# what is "          Prevalence " - why do we need it.     
#| PREVALENCE = P / P+N
#| How often does the positive condition actually occur in our sample?

# what is "      Detection Rate " - why do we need it.     
#| DETECTION RATE = TP / (TP + TN + FP + FN)
#| 

# what is "Detection Prevalence " - why do we need it.     
#| DETECTION PREVALENCE = (TP + FP) / (TP + TN + FP + FN)
#| 

# what does predict function do?
#| When given an object of class 'tree' as the first argument, such as one 
#| created by the function rpart(), it returns a vector of predicted responses 
#| from the fitted tree object.

# What is ROC - why does it do and why do we need it
#| ROC stands for "receiver operating characteristic (ROC) curve".  A visual 
#| method to measure the performance of a binary classifier.  
#| It is generated by plotting the True Positive Rate (Sensitivity) against the 
#| False Positive Rate (Specificity) as you vary the threshold for assigning 
#| observations to a given class. 
#| The area under that curve (AUC) is a way to summarize the performance using
#| a single number.



# https://www.r-bloggers.com/2021/04/decision-trees-in-r/
# https://www.guru99.com/r-decision-trees.html


#install.packages(c("DAAG", "party", "rpart", "rpart.plot", "mlbench", "caret", "pROC", "tree"  ))

# Load Library

library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(caret)
library(pROC)
library(tree)

# Getting Data -Email Spam Detection

str(spam7) 
# data.frame':  4601 obs. of  7 variables:
#  $ crl.tot: num  278 1028 2259 191 191 ...
#  $ dollar : num  0 0.18 0.184 0 0 0 0.054 0 0.203 0.081 ...
#  $ bang   : num  0.778 0.372 0.276 0.137 0.135 0 0.164 0 0.181 0.244 ...
#  $ money  : num  0 0.43 0.06 0 0 0 0 0 0.15 0 ...
#  $ n000   : num  0 0.43 1.16 0 0 0 0 0 0 0.19 ...
#  $ make   : num  0 0.21 0.06 0 0 0 0 0 0.15 0.06 ...
#  $ yesno  : Factor w/ 2 levels "n","y": 2 2 2 2 2 2 2 2 2 2 ...

# Total 4601 observations and 7 variables.

# data description
?spam7




 mydata <- spam7
 
# Data Partition
 set.seed(1234)
 ind <- sample(2, nrow(mydata), replace = T, prob = c(0.5, 0.5))
 train <- mydata[ind == 1,]
 test <- mydata[ind == 2,]
# Tree Classification

?rpart # algorithm that creates the dicisions
?rpart.object. # algorithm that creates the dicisions
 
tree <- rpart(yesno ~., data = train)
rpart.plot(tree)
 

 printcp(tree)
 # Classification tree:
 #   rpart(formula = yesno ~ ., data = train)
 # Variables actually used in tree construction:
 #   [1] bang    crl.tot dollar
 # Root node error: 900/2305 = 0.39046
 # n= 2305
 # CP nsplit rel error  xerror     xstd
 # 1 0.474444      0   1.00000 1.00000 0.026024
 # 2 0.074444      1   0.52556 0.56556 0.022128
 # 3 0.010000      3   0.37667 0.42111 0.019773
 plotcp(tree)

 
 # https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf
 # – cp: The threshold complexity parameter (you realy have to
 #understand the theory to fully understand what is going on behind the seen)
 
 # You can change the cp value according to your data set. 
 # Please note lower cp value means bigger the tree. 
 #If you are using too lower cp that leads to overfitting also.
 # 
 tree <- rpart(yesno ~., data = train,cp=0.07444)
 
 
# Confusion matrix -train

 p <- predict(tree, train, type = 'class')
 confusionMatrix(p, train$yesno, positive="y")
 
#Please make sure you mention positive classes in the confusion matrix.
# 
#  Confusion Matrix and Statistics
#  Reference
#  Prediction    n    y
#  n 1278  212
#  y  127  688
#  Accuracy : 0.8529         
#  95% CI : (0.8378, 0.8671)
#  No Information Rate : 0.6095         
#  P-Value [Acc > NIR] : < 2.2e-16      
#  Kappa : 0.6857         
#  Mcnemar's Test P-Value : 5.061e-06      
#            Sensitivity : 0.7644         
#             Specificity : 0.9096         
#          Pos Pred Value : 0.8442         
#          Neg Pred Value : 0.8577         
#              Prevalence : 0.3905         
#          Detection Rate : 0.2985         
#    Detection Prevalence : 0.3536         
#       Balanced Accuracy : 0.8370         
#        'Positive' Class : y
# Model has 85% accuracy
# 
#  

#ROC
 p1 <- predict(tree, test, type = 'prob')
 p1 <- p1[,2]
 r <- multiclass.roc(test$yesno, p1, percent = TRUE)
 roc <- r[['rocs']]
 r1 <- roc[[1]]
 plot.roc(r1,
          print.auc=TRUE,
          auc.polygon=TRUE,
          grid=c(0.1, 0.2),
          grid.col=c("green", "red"),
          max.auc.polygon=TRUE,
          auc.polygon.col="lightblue",
          print.thres=TRUE,
          main= 'ROC Curve')
 
 # Method 2- Regression  Tree
 
 data('BostonHousing')
 mydata <- BostonHousing
 
 #Data Partition
 set.seed(1234)
 ind <- sample(2, nrow(mydata), replace = T, prob = c(0.5, 0.5))
 train <- mydata[ind == 1,]
 test <- mydata[ind == 2,]
 #Regression tree
 tree <- rpart(medv ~., data = train)
 rpart.plot(tree)
 
 
 
 printcp(tree)
 # Regression tree:
 #   rpart(formula = medv ~ ., data = train)
 # Variables actually used in tree construction:
 #   [1] age   crim  lstat rm  
 # Root node error: 22620/262 = 86.334
 # n= 262
 # CP nsplit rel error  xerror     xstd
 # 0.469231      0   1.00000 1.01139 0.115186
 # 2 0.128700      1   0.53077 0.62346 0.080154
 # 3 0.098630      2   0.40207 0.51042 0.076055
 # 4 0.033799      3   0.30344 0.42674 0.069827
 # 5 0.028885      4   0.26964 0.39232 0.066342
 # 6 0.028018      5   0.24075 0.37848 0.066389
 # 7 0.015141      6   0.21274 0.34877 0.065824
 # 8 0.010000      7   0.19760 0.33707 0.065641
 rpart.rules(tree)
 #medv                                                                       
 # 13 when lstat >=        14.8 & crim >= 5.8   
 # 17 when lstat >=        14.8 & crim <  5.8    
 # 22 when lstat is 7.2 to 14.8 & rm <  6.6                                    
 # 26 when lstat <  7.2         & rm <  6.8        & age <  89                 
 # 29 when lstat is 7.2 to 14.8 & rm >=        6.6                             
 # 33 when lstat <  7.2         & rm is 6.8 to 7.5 & age <  89                 
 # 40 when lstat <  7.2         & rm <  7.5        & age >= 89                 
 # 45 when lstat <  7.2         & rm >=        7.5       
 
 plotcp(tree)
 
 
 
 # Predict
 p <- predict(tree, train)
 # Root Mean Square Error
 
 sqrt(mean((train$medv-p)^2))
 #4.130294
 
 # R Square
 
 (cor(train$medv,p))^2
 #0.8024039
 
 # Conclusion
 # In the regression model, the r square value is 80% 
 # and RMSE is 4.13, not bad at all.
 # .In this way, you can make use of 
 # Decision classification regression tree models.
 # 
 
 
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a444b6c-c12d-4f39-b5f2-590512a72981",
   "metadata": {},
   "source": [
    "# DAT 301 - Assignment 3: Neural Networks\n",
    "- Name: Colin Bowers (bowerc3)\n",
    "- Date: Feb 22, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98384c92-bd8b-4208-ac33-b042cf43ae4b",
   "metadata": {},
   "source": [
    "**1) Why do we need deep learning? Why is machine learning not enough? Mention at most three bullets (reasons) and briefly explain them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee375df-66e0-4ff0-871b-b782a25babff",
   "metadata": {},
   "source": [
    "1. **Feature Engineering.**  ML often requires extensive, manual feature engeineering and selection.  Deep learning eliminates this need allowing the models to discover and use features on its own.\n",
    "2. **Unstructured Data.**  Conventional ML tends to be challenged with unstructured data like images, audio and text.  Deep learning excels in handling this type of data.\n",
    "3. **Hierarchical Features.**  Traditional ML models sometimes stuggle with intricate hierachical patterns in data.  For example, with image regonition. Deep learning models, with multiple layers, does well with automatically learning these complex relationships.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b4431-cb6f-4d7a-8c3e-e70bbae00718",
   "metadata": {},
   "source": [
    "**2) Why is step function problematic to use in neural networks as an activation function? (hint: think of the loss function)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af688a89-312c-4fde-8a68-2e88030d1ac1",
   "metadata": {},
   "source": [
    "- Does allow for gradual changes in the output given small changes with the input.  This lack of sensitivity hinders the learning process since the model cannot effectively adjust its weights.\n",
    "- Lacks the continuous range of values needed for expressing the complexity of most real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50edb01-1497-4602-bcc4-2ab94a57404c",
   "metadata": {},
   "source": [
    "**3) Why is the squared error loss function (`(predicted-actual)^2` ) more convenient than the norm function (`||predicted-actual||`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf378b-0023-4236-89ad-839d7a48dccc",
   "metadata": {},
   "source": [
    "- Penalizes large errors more than smaller ones making it more robust with outliers and prioritizes accurate preditictions.\n",
    "- Simplifies mathematical operations, for example, differntiation used for certain algorithms (like Gradient Dscent).\n",
    "- Directly related to Guassian likelihood which makes it easier to interpret with probability and statistical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529578b-54e8-4290-a907-08fbc9fc5e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
